

This section discusses the development of certifiers for efficient and trustworthy DNNs. It explains how domain experts design a set of safety specifications to define the expected network behavior in different real-world scenarios. It also explains the inefficiency of existing certifiers when certifying a large and diverse set of specifications on a single DNN. To overcome this limitation, recent works have developed general mechanisms to enable incremental certification by reusing proofs across multiple specifications and DNNs. This section also discusses certified training, which involves defining a robust loss function LR for each point x in the DNN output z = f (x). The DNN parameters can be updated during training to minimize the maximum value of LR. Adversarial training methods compute a lower bound on the worst-case robust loss by heuristically computing a point x at which the robust loss is high. Certified training, on the other hand, involves computing the point z in g(α(ϕ)) where the robust loss is maximum and backpropagating the resulting loss to update the model parameters.