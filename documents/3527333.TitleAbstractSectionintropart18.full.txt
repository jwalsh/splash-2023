Title-Abstract. Section intro
 optimized version of the generated code by SDQL is in average 3Ã— and
2Ã— faster than the COO and CSR represenations of SciPy, respectively, thanks to fusion and the
efficient low-level code generated by SDQL.
Sparse Tensor Processing. Next, we consider three higher-order tensor workloads on NELL-2, a
real world dataset coming from the Never-Learning project [Carlson et al. 2010].
Table 3 shows the performance comparison for these workloads. We observe that especially for
a medium range of sparsity SDQL is faster than taco (from 1.4Ã— to 23Ã—). For sparser scenarios,

Proc. ACM Program. Lang., Vol, No. OOPSLA1, Article 89. Publication date: April 2022.

2âˆ’112âˆ’92âˆ’72âˆ’52âˆ’3Density110100100010000Run Time (ms)Time OutTime OutSDQL (flat)SDQL (curried)SDQL (fused)SciPy (COO)SciPy (CSR)NumPy100k200k400k800kDimension (N)110100100010000Run Time (ms)Time OutTime Out
Functional Collection Programming with Semi-ring Dictionaries

89:23

Table 3. Run time results of SDQL and taco for TTV, TTM, and MTTKRP on Nell-2 dataset by varying the
sparsity of the second and third operands. Both systems use a sparse representation for all tensor modes.

Sparsity

2âˆ’11

2âˆ’9

2âˆ’7

2âˆ’5

2âˆ’3

Kernel

LA Formulation

SDQL

taco

SDQL

taco

SDQL

taco

SDQL

taco

SDQL

taco

TTV
TTM
MTTKRP ğ´ğ‘– ğ‘— = Î£ğ‘˜,ğ‘™ ğµğ‘–ğ‘˜ğ‘™ğ¶ğ‘˜ ğ‘— ğ·ğ‘™ ğ‘—

ğ´ğ‘– ğ‘— = Î£ğ‘˜ ğµğ‘– ğ‘—ğ‘˜ğ‘ğ‘˜
ğ´ğ‘– ğ‘—ğ‘˜ = Î£ğ‘˜ ğµğ‘– ğ‘—ğ‘™ğ¶ğ‘˜ğ‘™

621.8
466.3
4534.2 5936.2
5.6

4.3

621.8
544.9
4679.6 7851.6
18.4

17.3

866.2

632.0
4764.2 15563.9
32.2

60.4

661.8
2088.1
5189.2 46153.7
103.2

388.1

6742.7

729.4
7146.6 169865.5
723.8

4371.1

(a) Biomedical query with different optimizations in
SDQL and Trance [Smith et al. 2020]/MLLib.

(b) Retail forecasting using different optimizations
in SDQL and LMFAO [Schleich et al. 2019].
Fig. 17. Run time results for computing covariance matrix over nested and relational data.

taco shows better performance (up to 1.3Ã—), thanks to the DCSR format and its merge-based
multiplications. A similar observation on hash/CSR been made in [Chou et al. 2018].

9.4 Hybrid LA/DB Workload
As the final set of experiments, we consider hybrid workloads that involve linear algebra
processing. Figure 17 shows the experimental results for computing the covariance matrix. We
consider experiments that use 1) nested, 2) relational, and 3) normalized matrix input datasets.
Nested Data. For nested data, we use our motivating biomedical example as the workload and
variant data from 1000 genomes dataset asSudmant et al. 2015]. The experiment involves
computing the covariance matrix of the join of Genes and Variants relations, by
number of the elements of the former relation; this is synonymous to increasing the number of
features in the covariant matrix by approximately 15, 30, 55, and 70. We consider the following four
versions of the generated code from SDQL: 1) un code that uses uncurried representation
for matrices, 2) curried version that uses curried representation for intermediate matrices, 3) a
version that uses hash join for joining Genes and Variants, and 4) a version obtained by fusing
intermediate dictionaries resulting from grouping and matrix transpose. As our competitor, we
only consider Trance [Smith et al. 2020] for the query processing part, which implements an
extension of NRC+ with aggregation called NRCğ‘ğ‘”ğ‘” and uses Spark MLLib [Meng et al. 2016] for
the linear algebra processing. This is because in-database machine learning frameworks such as
IFAQ [Shaikhha et al. 2020], LMFAO [Schleich et al. 2019], and Morpheus [Chen et al. 2017; Li et al.
2019] do not relations.

As Figure 17a shows, we observe that using curried representation gives asymptotic improve-
ments, and allows SDQL to scale to larger inputs. Furthermore, using hash join, gives an additionalÃ— speedup. This speedup can be larger for larger Genes relations. Performing fusion results in an
additional 50% speedup thanks to the removal of intermediate dictionaries and less loop traversals.
Finally, we observe around one order of magnitude performance improvement overMLLib
thanks to the lack of need for unnesting, which is enabled by nested dictionaries provided by SDQL.
Relational Data. Next compute the covariance matrix over the result of join of relational input.
To do so, we use the semi-ring of the covariance matrix (cf. Section 8.3). We use two real-world

Proc. ACM Program. Lang., Vol. 6, No. OOPSLA1, Article 89. Publication date: April

5K18K32K45KNumber of Top Level Records100100010000100000Run Time (ms)Time OutTime OutTime OutSDQL (unoptimized)SDQL (curried)SDQL (hash join)SDQL (fused)Trance/MLLibFavorita (Small)Retailer (Small)Favorita (Large