Title-Abstract. Section intro
Building Trust and Safety in Artificial

Intelligence with Abstract Interpretation

Gagandeep Singh1,2[0000−0002−9299−2961]

1 University at Urbana-Champaign (UIUC), USA

2 VMware Research, USA ggnds@illinois.edu

1

Introduction

Deep neural networks (D) are currently the dominant technology in artificial
intelligence (AI) and have shown impressive performance in diverse applications
including autonomous driving [9], medical diagnosis [2], and text generation [10]., their black-box construction [46] and vulnerability against environmen-
tal and adversarial noise [57, 30] have raised concerns about their safety, when
deployed in the real world. Standard training [28] optimizes the model’sbut does not take into account desirable safety properties such as robustness [48],
fairness [18], and monotonicity [49]. The standard practice of testing and inter-
preting D on set of unseen test inputs cannot guarantee safe
and trustworthy D on new inputs seen during deployment [59, 66].
This is because the DNN can misbehave if the inputs observed during deploy-
ment deviate even slightly from those in the test set [36, 20, 23].

To address these limitations, there is growing work on checking the safety of
DNN models
[5, 52, 51, 53, 44, 70, 58, 68, 3, 27, 50, 65, 31, 62, 11, 61, 25, 43, 17, 42,
45] and interpreting their behavior [7], on an infinite set of unseen inputs using
formal certification. Testing and interpreting with formal methods provide a
more reliable metric for measuring a model’s safety than standard methods [12].
Formal methods can also be used during training [22, 38, 69, 74, 72, 40, 6] to guide
the model to satisfy desirable safety and trustworthy properties.
DNN certification problem. The certification problem consists of two main
components: (i) a trained DNN f, (ii) a property specification in the form of
a tuple (ϕ, ψ) containing symbolic formulas ϕ and ψ. Here the formula ϕ is a
precondition specifying the set of inputs on which, the DNN should not mis-
behave. The formula ψ is a postcondition that determines constraints that the
DNN outputs f (ϕ) [26] or its gradients f′(ϕ) [33, 34] corresponding to the in-
puts in ϕ should satisfy, for its behaviors to be considered safe and trustworthy.
A DNN certifier tries to check whether f (ϕ) ⊆ ψ (or f′(ϕ) ⊆ ψ) holds. Both
ϕ, ψ are typically specified as disjunctions of convex polyhedra. The property
specifications are domain dependent and usually designed by DNN developers.
Local vs global properties. The precondition ϕ for local properties defines
a local neighborhood around a sample input from the test set. For example,
given a test image correctly classified as a car by a DNN, the popular local
robustness property specifies that all images generated by rotating the original


Fig. 1: Neural network certification with abstract interpretation involves com-
puting an abstract element (in blue) containing the true network output f (ϕ)
(in white) at each layer using the corresponding abstract transformer.

image within ±5 degrees are also classified as a car [5]. In contrast, ϕ for global
properties does not depend upon a test input. For domains where the input
features have semantic meaning, e.g., air traffic collision avoidance systems [26]
or security classifiers [13], global properties can be specified by defining a valid
range for the input features expected in a real-world deployment. Certifying
global properties yields stronger safety guarantees, however, they are difficult to
formulate for popular domains, such as vision and NLP, where the individual
features processed by the DNN have no semantic meaning. While certifying local
properties is not ideal, the local certification results enable testing the safety of
the model on an infinite set of unseen inputs, not possible with standard methods.

2 Certification for Testing Model Safety

DNN certification can be seen as an instance of program verification (DNNs
can be written as programs) making it undecidable. State-of-the-art certifiers
are therefore incomplete in general. These certifiers can be formulated using the
elegant framework of abstract interpretation [15]. While abstract interpretation-
based certifiers can certify both local and global properties, for the remainder of
this paper, we focus on the certification of local properties as they are more com-
mon in real-world applications. Figure 1 shows the high-level idea behind DNN
certification with abstract interpretation. Here, the certifier is parameterized by
the choice of an abstract domain. The certifier first computes an abstract ele-
ment α(ϕ) ⊇ ϕ that includes the input region ϕ. Next, the analyzer symbolically
propagates α(ϕ) through the different layers of the network. At each layer, the
analyzer computes an abstract element (in blue) overapproximating the exact
layer output (in white) corresponding to ϕ. The element is computed by apply-
ing an abstract